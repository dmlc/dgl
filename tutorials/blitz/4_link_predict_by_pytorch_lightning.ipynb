{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8vIpGlT-XsVF"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install torchlayers\n",
    "# !pip install torchmetric\n",
    "# !pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html\n",
    "#!pip install rich --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ODP6IzWmx6DV"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Link Prediction using Graph Neural Networks\n",
    "===========================================\n",
    "\n",
    "In the :doc:`introduction <1_introduction>`, you have already learned\n",
    "the basic workflow of using GNNs for node classification,\n",
    "i.e. predicting the category of a node in a graph. This tutorial will\n",
    "teach you how to train a GNN for link prediction, i.e. predicting the\n",
    "existence of an edge between two arbitrary nodes in a graph.\n",
    "\n",
    "By the end of this tutorial you will be able to\n",
    "\n",
    "-  Build a GNN-based link prediction model.\n",
    "-  Train and evaluate the model on a small DGL-provided dataset.\n",
    "\n",
    "(Time estimate: 28 minutes)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import dgl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGXOjFST_FwW",
    "outputId": "ccd5fd3b-bf5f-4c89-9301-90a94e9f21c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######################################################################\n",
    "# Overview of Link Prediction with GNN\n",
    "# ------------------------------------\n",
    "#\n",
    "# Many applications such as social recommendation, item recommendation,\n",
    "# knowledge graph completion, etc., can be formulated as link prediction,\n",
    "# which predicts whether an edge exists between two particular nodes. This\n",
    "# tutorial shows an example of predicting whether a citation relationship,\n",
    "# either citing or being cited, between two papers exists in a citation\n",
    "# network.\n",
    "#\n",
    "# This tutorial formulates the link prediction problem as a binary classification\n",
    "# problem as follows:\n",
    "#\n",
    "# -  Treat the edges in the graph as *positive examples*.\n",
    "# -  Sample a number of non-existent edges (i.e. node pairs with no edges\n",
    "#    between them) as *negative* examples.\n",
    "# -  Divide the positive examples and negative examples into a training\n",
    "#    set and a test set.\n",
    "# -  Evaluate the model with any binary classification metric such as Area\n",
    "#    Under Curve (AUC).\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#    The practice comes from\n",
    "#    `SEAL <https://papers.nips.cc/paper/2018/file/53f0d7c537d99b3824f0f99d62ea2428-Paper.pdf>`__,\n",
    "#    although the model here does not use their idea of node labeling.\n",
    "#\n",
    "# In some domains such as large-scale recommender systems or information\n",
    "# retrieval, you may favor metrics that emphasize good performance of\n",
    "# top-K predictions. In these cases you may want to consider other metrics\n",
    "# such as mean average precision, and use other negative sampling methods,\n",
    "# which are beyond the scope of this tutorial.\n",
    "#\n",
    "# Loading graph and features\n",
    "# --------------------------\n",
    "#\n",
    "# Following the :doc:`introduction <1_introduction>`, this tutorial\n",
    "# first loads the Cora dataset.\n",
    "#\n",
    "\n",
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Prepare training and testing sets\n",
    "# ---------------------------------\n",
    "#\n",
    "# This tutorial randomly picks 10% of the edges for positive examples in\n",
    "# the test set, and leave the rest for the training set. It then samples\n",
    "# the same number of edges for negative examples in both sets.\n",
    "#\n",
    "\n",
    "# Split edge set for training and testing\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# When training, you will need to remove the edges in the test set from\n",
    "# the original graph. You can do this via ``dgl.remove_edges``.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#    ``dgl.remove_edges`` works by creating a subgraph from the\n",
    "#    original graph, resulting in a copy and therefore could be slow for\n",
    "#    large graphs. If so, you could save the training and test graph to\n",
    "#    disk, as you would do for preprocessing.\n",
    "#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rJptuIA1_JuV"
   },
   "outputs": [],
   "source": [
    "\n",
    "######################################################################\n",
    "# Define a GraphSAGE model\n",
    "# ------------------------\n",
    "#\n",
    "# This tutorial builds a model consisting of two\n",
    "# `GraphSAGE <https://arxiv.org/abs/1706.02216>`__ layers, each computes\n",
    "# new node representations by averaging neighbor information. DGL provides\n",
    "# ``dgl.nn.SAGEConv`` that conveniently creates a GraphSAGE layer.\n",
    "#\n",
    "\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vkGiidjO_MJ1"
   },
   "outputs": [],
   "source": [
    "\n",
    "######################################################################\n",
    "# The model then predicts the probability of existence of an edge by\n",
    "# computing a score between the representations of both incident nodes\n",
    "# with a function (e.g. an MLP or a dot product), which you will see in\n",
    "# the next section.\n",
    "#\n",
    "# .. math::\n",
    "#\n",
    "#\n",
    "#    \\hat{y}_{u\\sim v} = f(h_u, h_v)\n",
    "#\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Positive graph, negative graph, and ``apply_edges``\n",
    "# ---------------------------------------------------\n",
    "#\n",
    "# In previous tutorials you have learned how to compute node\n",
    "# representations with a GNN. However, link prediction requires you to\n",
    "# compute representation of *pairs of nodes*.\n",
    "#\n",
    "# DGL recommends you to treat the pairs of nodes as another graph, since\n",
    "# you can describe a pair of nodes with an edge. In link prediction, you\n",
    "# will have a *positive graph* consisting of all the positive examples as\n",
    "# edges, and a *negative graph* consisting of all the negative examples.\n",
    "# The *positive graph* and the *negative graph* will contain the same set\n",
    "# of nodes as the original graph.  This makes it easier to pass node\n",
    "# features among multiple graphs for computation.  As you will see later,\n",
    "# you can directly feed the node representations computed on the entire\n",
    "# graph to the positive and the negative graphs for computing pair-wise\n",
    "# scores.\n",
    "#\n",
    "# The following code constructs the positive graph and the negative graph\n",
    "# for the training set and the test set respectively.\n",
    "#\n",
    "\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])\n",
    "\n",
    "\n",
    "\n",
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes()) # we only need the topology information \n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "texePH3T_NwW"
   },
   "outputs": [],
   "source": [
    "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class Sage4LinkPrediction(pl.LightningModule):\n",
    "  def __init__(self,gnn,predictor,device):\n",
    "    super().__init__()\n",
    "    self.gnn = gnn\n",
    "    self.pred = predictor\n",
    "    self.train_auc = torchmetrics.AUROC(pos_label=1)\n",
    "    self.val_auc = torchmetrics.AUROC(pos_label=1)\n",
    "    self.automatic_optimization = True\n",
    "    self.save_hyperparameters('device') # save the hyperparams to model.params\n",
    "\n",
    "\n",
    "  def forward(self,g):\n",
    "    h = self.gnn(g, g.ndata['feat'])\n",
    "    \n",
    "    return h\n",
    "\n",
    "  def training_step(self,batch,batch_idx):\n",
    "    train_g,train_pos_g,train_neg_g = batch\n",
    "    h = self(train_g)\n",
    "    pos_score = self.pred(train_pos_g, h)\n",
    "    neg_score = self.pred(train_neg_g, h)\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]).to(self.hparams.device), torch.zeros(neg_score.shape[0]).to(self.hparams.device)]) # make sure all tensors to be on the same device\n",
    "    # a better way is to use register buffer in \"__init__\" or define the labels in dataloader\n",
    "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    self.train_auc(scores,labels.long())\n",
    "    self.log_dict({'train-loss':loss,'train-auc':self.train_auc},prog_bar=True,on_step=True,on_epoch=True,batch_size=1)\n",
    "    self.h = h # for validation\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self,batch,batch_idx):\n",
    "    test_pos_g,test_neg_g = batch\n",
    "    pos_score = self.pred(test_pos_g, self.h)\n",
    "    neg_score = self.pred(test_neg_g, self.h)\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]).to(self.hparams.device), torch.zeros(neg_score.shape[0]).to(self.hparams.device)])\n",
    "    self.val_auc(scores,labels.long())\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(),lr=1e-2,weight_decay=1e-7)\n",
    "    return [optimizer]\n",
    "\n",
    "  def prediction_step(self,batch,batch_idx):\n",
    "    g=batch\n",
    "    return self(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YbjGTPS-x6FO"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######################################################################\n",
    "# The benefit of treating the pairs of nodes as a graph is that you can\n",
    "# use the ``DGLGraph.apply_edges`` method, which conveniently computes new\n",
    "# edge features based on the incident nodes’ features and the original\n",
    "# edge features (if applicable).\n",
    "#\n",
    "# DGL provides a set of optimized builtin functions to compute new\n",
    "# edge features based on the original node/edge features. For example,\n",
    "# ``dgl.function.u_dot_v`` computes a dot product of the incident nodes’\n",
    "# representations for each edge.\n",
    "#\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# You can also write your own function if it is complex.\n",
    "# For instance, the following module produces a scalar score on each edge\n",
    "# by concatenating the incident nodes’ features and passing it to an MLP.\n",
    "#\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# .. note::\n",
    "#\n",
    "#    The builtin functions are optimized for both speed and memory.\n",
    "#    We recommend using builtin functions whenever possible.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#    If you have read the :doc:`message passing\n",
    "#    tutorial <3_message_passing>`, you will notice that the\n",
    "#    argument ``apply_edges`` takes has exactly the same form as a message\n",
    "#    function in ``update_all``.\n",
    "#\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Training loop\n",
    "# -------------\n",
    "#\n",
    "# After you defined the node representation computation and the edge score\n",
    "# computation, you can go ahead and define the overall model, loss\n",
    "# function, and evaluation metric.\n",
    "#\n",
    "# The loss function is simply binary cross entropy loss.\n",
    "#\n",
    "# .. math::\n",
    "#\n",
    "#\n",
    "#    \\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\n",
    "#\n",
    "# The evaluation metric in this tutorial is AUC.\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399,
     "referenced_widgets": [
      "f40093e314784b32be4254270d1133f2",
      "d7648df0077a4618ad0d6a03df24a266"
     ]
    },
    "id": "bNqgc9PEHp13",
    "outputId": "0ca8ea91-816c-4f12-af8f-8aaa54acb1cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ gnn       │ GraphSAGE    │ 46.4 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ pred      │ DotPredictor │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ train_auc │ AUROC        │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ val_auc   │ AUROC        │      0 │\n",
       "└───┴───────────┴──────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ gnn       │ GraphSAGE    │ 46.4 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ pred      │ DotPredictor │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ train_auc │ AUROC        │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ val_auc   │ AUROC        │      0 │\n",
       "└───┴───────────┴──────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 46.4 K                                                                     \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
       "<span style=\"font-weight: bold\">Total params</span>: 46.4 K                                                                         \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 46.4 K                                                                     \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
       "\u001b[1mTotal params\u001b[0m: 46.4 K                                                                         \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40093e314784b32be4254270d1133f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "# The training loop goes as follows:\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#    This tutorial does not include evaluation on a validation\n",
    "#    set. In practice you should save and evaluate the best model based on\n",
    "#    performance on the validation set.\n",
    "#\n",
    "\n",
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "from torch.utils.data import DataLoader\n",
    "train_g_dataloader =DataLoader([[train_g,train_pos_g,train_neg_g]],batch_size=None)\n",
    "test_g_dataloader =DataLoader([[test_pos_g,test_neg_g]],batch_size=None)\n",
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "sage4linkpred = Sage4LinkPrediction(model,pred,device)\n",
    "\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "trainer = pl.Trainer(\n",
    "  fast_dev_run=False,\n",
    "  max_epochs=10,\n",
    "  gpus=1,\n",
    "  precision=32,\n",
    "  check_val_every_n_epoch=1,\n",
    "  val_check_interval=1.0,\n",
    "  num_sanity_val_steps=0,\n",
    "  callbacks=[RichProgressBar()],\n",
    ")\n",
    "trainer.fit(sage4linkpred,train_g_dataloader,test_g_dataloader)\n",
    "\n",
    "\n",
    "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
    "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSy7kk3XL5GM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "dgl官方教程的完整实现by lightning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d7648df0077a4618ad0d6a03df24a266": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f40093e314784b32be4254270d1133f2": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_d7648df0077a4618ad0d6a03df24a266",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 9    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #000000; text-decoration-color: #000000\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">33.77it/s</span> <span style=\"color: #000000; text-decoration-color: #000000\">loss: 0.661 v_num: 5     </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-loss_step: 0.603   </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-auc_step: 0.874    </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-loss_epoch: 0.621  </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-auc_epoch: 0.859   </span>\n</pre>\n",
         "text/plain": "Epoch 9    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[30m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m33.77it/s\u001b[0m \u001b[30mloss: 0.661 v_num: 5     \u001b[0m\n                                                                    \u001b[30mtrain-loss_step: 0.603   \u001b[0m\n                                                                    \u001b[30mtrain-auc_step: 0.874    \u001b[0m\n                                                                    \u001b[30mtrain-loss_epoch: 0.621  \u001b[0m\n                                                                    \u001b[30mtrain-auc_epoch: 0.859   \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
