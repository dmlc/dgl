{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dgl官方教程的完整实现by lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f40093e314784b32be4254270d1133f2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d7648df0077a4618ad0d6a03df24a266",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 9    \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[30m2/2\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m33.77it/s\u001b[0m \u001b[30mloss: 0.661 v_num: 5     \u001b[0m\n                                                                    \u001b[30mtrain-loss_step: 0.603   \u001b[0m\n                                                                    \u001b[30mtrain-auc_step: 0.874    \u001b[0m\n                                                                    \u001b[30mtrain-loss_epoch: 0.621  \u001b[0m\n                                                                    \u001b[30mtrain-auc_epoch: 0.859   \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 9    <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #000000; text-decoration-color: #000000\">2/2</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">33.77it/s</span> <span style=\"color: #000000; text-decoration-color: #000000\">loss: 0.661 v_num: 5     </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-loss_step: 0.603   </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-auc_step: 0.874    </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-loss_epoch: 0.621  </span>\n                                                                    <span style=\"color: #000000; text-decoration-color: #000000\">train-auc_epoch: 0.859   </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d7648df0077a4618ad0d6a03df24a266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8vIpGlT-XsVF"
      },
      "outputs": [],
      "source": [
        "# !pip install pytorch-lightning\n",
        "# !pip install torchlayers\n",
        "# !pip install torchmetric\n",
        "# !pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html\n",
        "#!pip install rich --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Link Prediction using Graph Neural Networks\n",
        "===========================================\n",
        "\n",
        "In the :doc:`introduction <1_introduction>`, you have already learned\n",
        "the basic workflow of using GNNs for node classification,\n",
        "i.e. predicting the category of a node in a graph. This tutorial will\n",
        "teach you how to train a GNN for link prediction, i.e. predicting the\n",
        "existence of an edge between two arbitrary nodes in a graph.\n",
        "\n",
        "By the end of this tutorial you will be able to\n",
        "\n",
        "-  Build a GNN-based link prediction model.\n",
        "-  Train and evaluate the model on a small DGL-provided dataset.\n",
        "\n",
        "(Time estimate: 28 minutes)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "import dgl\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ],
      "metadata": {
        "id": "ODP6IzWmx6DV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "######################################################################\n",
        "# Overview of Link Prediction with GNN\n",
        "# ------------------------------------\n",
        "#\n",
        "# Many applications such as social recommendation, item recommendation,\n",
        "# knowledge graph completion, etc., can be formulated as link prediction,\n",
        "# which predicts whether an edge exists between two particular nodes. This\n",
        "# tutorial shows an example of predicting whether a citation relationship,\n",
        "# either citing or being cited, between two papers exists in a citation\n",
        "# network.\n",
        "#\n",
        "# This tutorial formulates the link prediction problem as a binary classification\n",
        "# problem as follows:\n",
        "#\n",
        "# -  Treat the edges in the graph as *positive examples*.\n",
        "# -  Sample a number of non-existent edges (i.e. node pairs with no edges\n",
        "#    between them) as *negative* examples.\n",
        "# -  Divide the positive examples and negative examples into a training\n",
        "#    set and a test set.\n",
        "# -  Evaluate the model with any binary classification metric such as Area\n",
        "#    Under Curve (AUC).\n",
        "#\n",
        "# .. note::\n",
        "#\n",
        "#    The practice comes from\n",
        "#    `SEAL <https://papers.nips.cc/paper/2018/file/53f0d7c537d99b3824f0f99d62ea2428-Paper.pdf>`__,\n",
        "#    although the model here does not use their idea of node labeling.\n",
        "#\n",
        "# In some domains such as large-scale recommender systems or information\n",
        "# retrieval, you may favor metrics that emphasize good performance of\n",
        "# top-K predictions. In these cases you may want to consider other metrics\n",
        "# such as mean average precision, and use other negative sampling methods,\n",
        "# which are beyond the scope of this tutorial.\n",
        "#\n",
        "# Loading graph and features\n",
        "# --------------------------\n",
        "#\n",
        "# Following the :doc:`introduction <1_introduction>`, this tutorial\n",
        "# first loads the Cora dataset.\n",
        "#\n",
        "\n",
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Prepare training and testing sets\n",
        "# ---------------------------------\n",
        "#\n",
        "# This tutorial randomly picks 10% of the edges for positive examples in\n",
        "# the test set, and leave the rest for the training set. It then samples\n",
        "# the same number of edges for negative examples in both sets.\n",
        "#\n",
        "\n",
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# When training, you will need to remove the edges in the test set from\n",
        "# the original graph. You can do this via ``dgl.remove_edges``.\n",
        "#\n",
        "# .. note::\n",
        "#\n",
        "#    ``dgl.remove_edges`` works by creating a subgraph from the\n",
        "#    original graph, resulting in a copy and therefore could be slow for\n",
        "#    large graphs. If so, you could save the training and test graph to\n",
        "#    disk, as you would do for preprocessing.\n",
        "#\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGXOjFST_FwW",
        "outputId": "ccd5fd3b-bf5f-4c89-9301-90a94e9f21c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "######################################################################\n",
        "# Define a GraphSAGE model\n",
        "# ------------------------\n",
        "#\n",
        "# This tutorial builds a model consisting of two\n",
        "# `GraphSAGE <https://arxiv.org/abs/1706.02216>`__ layers, each computes\n",
        "# new node representations by averaging neighbor information. DGL provides\n",
        "# ``dgl.nn.SAGEConv`` that conveniently creates a GraphSAGE layer.\n",
        "#\n",
        "\n",
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "    \n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "rJptuIA1_JuV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "######################################################################\n",
        "# The model then predicts the probability of existence of an edge by\n",
        "# computing a score between the representations of both incident nodes\n",
        "# with a function (e.g. an MLP or a dot product), which you will see in\n",
        "# the next section.\n",
        "#\n",
        "# .. math::\n",
        "#\n",
        "#\n",
        "#    \\hat{y}_{u\\sim v} = f(h_u, h_v)\n",
        "#\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Positive graph, negative graph, and ``apply_edges``\n",
        "# ---------------------------------------------------\n",
        "#\n",
        "# In previous tutorials you have learned how to compute node\n",
        "# representations with a GNN. However, link prediction requires you to\n",
        "# compute representation of *pairs of nodes*.\n",
        "#\n",
        "# DGL recommends you to treat the pairs of nodes as another graph, since\n",
        "# you can describe a pair of nodes with an edge. In link prediction, you\n",
        "# will have a *positive graph* consisting of all the positive examples as\n",
        "# edges, and a *negative graph* consisting of all the negative examples.\n",
        "# The *positive graph* and the *negative graph* will contain the same set\n",
        "# of nodes as the original graph.  This makes it easier to pass node\n",
        "# features among multiple graphs for computation.  As you will see later,\n",
        "# you can directly feed the node representations computed on the entire\n",
        "# graph to the positive and the negative graphs for computing pair-wise\n",
        "# scores.\n",
        "#\n",
        "# The following code constructs the positive graph and the negative graph\n",
        "# for the training set and the test set respectively.\n",
        "#\n",
        "\n",
        "train_g = dgl.remove_edges(g, eids[:test_size])\n",
        "\n",
        "\n",
        "\n",
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes()) # we only need the topology information \n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "metadata": {
        "id": "vkGiidjO_MJ1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class Sage4LinkPrediction(pl.LightningModule):\n",
        "  def __init__(self,gnn,predictor,device):\n",
        "    super().__init__()\n",
        "    self.gnn = gnn\n",
        "    self.pred = predictor\n",
        "    self.train_auc = torchmetrics.AUROC(pos_label=1)\n",
        "    self.val_auc = torchmetrics.AUROC(pos_label=1)\n",
        "    self.automatic_optimization = True\n",
        "    self.save_hyperparameters('device') # save the hyperparams to model.params\n",
        "\n",
        "\n",
        "  def forward(self,g):\n",
        "    h = self.gnn(g, g.ndata['feat'])\n",
        "    \n",
        "    return h\n",
        "\n",
        "  def training_step(self,batch,batch_idx):\n",
        "    train_g,train_pos_g,train_neg_g = batch\n",
        "    h = self(train_g)\n",
        "    pos_score = self.pred(train_pos_g, h)\n",
        "    neg_score = self.pred(train_neg_g, h)\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]).to(self.hparams.device), torch.zeros(neg_score.shape[0]).to(self.hparams.device)]) # make sure all tensors to be on the same device\n",
        "    # a better way is to use register buffer in \"__init__\" or define the labels in dataloader\n",
        "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
        "    self.train_auc(scores,labels.long())\n",
        "    self.log_dict({'train-loss':loss,'train-auc':self.train_auc},prog_bar=True,on_step=True,on_epoch=True,batch_size=1)\n",
        "    self.h = h # for validation\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self,batch,batch_idx):\n",
        "    test_pos_g,test_neg_g = batch\n",
        "    pos_score = self.pred(test_pos_g, self.h)\n",
        "    neg_score = self.pred(test_neg_g, self.h)\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]).to(self.hparams.device), torch.zeros(neg_score.shape[0]).to(self.hparams.device)])\n",
        "    self.val_auc(scores,labels.long())\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(),lr=1e-2,weight_decay=1e-7)\n",
        "    return [optimizer]\n",
        "\n",
        "  def prediction_step(self,batch,batch_idx):\n",
        "    g=batch\n",
        "    return self(g)\n"
      ],
      "metadata": {
        "id": "texePH3T_NwW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "######################################################################\n",
        "# The benefit of treating the pairs of nodes as a graph is that you can\n",
        "# use the ``DGLGraph.apply_edges`` method, which conveniently computes new\n",
        "# edge features based on the incident nodes’ features and the original\n",
        "# edge features (if applicable).\n",
        "#\n",
        "# DGL provides a set of optimized builtin functions to compute new\n",
        "# edge features based on the original node/edge features. For example,\n",
        "# ``dgl.function.u_dot_v`` computes a dot product of the incident nodes’\n",
        "# representations for each edge.\n",
        "#\n",
        "\n",
        "import dgl.function as fn\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# You can also write your own function if it is complex.\n",
        "# For instance, the following module produces a scalar score on each edge\n",
        "# by concatenating the incident nodes’ features and passing it to an MLP.\n",
        "#\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# .. note::\n",
        "#\n",
        "#    The builtin functions are optimized for both speed and memory.\n",
        "#    We recommend using builtin functions whenever possible.\n",
        "#\n",
        "# .. note::\n",
        "#\n",
        "#    If you have read the :doc:`message passing\n",
        "#    tutorial <3_message_passing>`, you will notice that the\n",
        "#    argument ``apply_edges`` takes has exactly the same form as a message\n",
        "#    function in ``update_all``.\n",
        "#\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Training loop\n",
        "# -------------\n",
        "#\n",
        "# After you defined the node representation computation and the edge score\n",
        "# computation, you can go ahead and define the overall model, loss\n",
        "# function, and evaluation metric.\n",
        "#\n",
        "# The loss function is simply binary cross entropy loss.\n",
        "#\n",
        "# .. math::\n",
        "#\n",
        "#\n",
        "#    \\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\n",
        "#\n",
        "# The evaluation metric in this tutorial is AUC.\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YbjGTPS-x6FO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# The training loop goes as follows:\n",
        "#\n",
        "# .. note::\n",
        "#\n",
        "#    This tutorial does not include evaluation on a validation\n",
        "#    set. In practice you should save and evaluate the best model based on\n",
        "#    performance on the validation set.\n",
        "#\n",
        "\n",
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "from torch.utils.data import DataLoader\n",
        "train_g_dataloader =DataLoader([[train_g,train_pos_g,train_neg_g]],batch_size=None)\n",
        "test_g_dataloader =DataLoader([[test_pos_g,test_neg_g]],batch_size=None)\n",
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
        "pred = DotPredictor()\n",
        "\n",
        "sage4linkpred = Sage4LinkPrediction(model,pred,device)\n",
        "\n",
        "from pytorch_lightning.callbacks import RichProgressBar\n",
        "trainer = pl.Trainer(\n",
        "  fast_dev_run=False,\n",
        "  max_epochs=10,\n",
        "  gpus=1,\n",
        "  precision=32,\n",
        "  check_val_every_n_epoch=1,\n",
        "  val_check_interval=1.0,\n",
        "  num_sanity_val_steps=0,\n",
        "  callbacks=[RichProgressBar()],\n",
        ")\n",
        "trainer.fit(sage4linkpred,train_g_dataloader,test_g_dataloader)\n",
        "\n",
        "\n",
        "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "f40093e314784b32be4254270d1133f2",
            "d7648df0077a4618ad0d6a03df24a266"
          ]
        },
        "id": "bNqgc9PEHp13",
        "outputId": "0ca8ea91-816c-4f12-af8f-8aaa54acb1cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ gnn       │ GraphSAGE    │ 46.4 K │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ pred      │ DotPredictor │      0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ train_auc │ AUROC        │      0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ val_auc   │ AUROC        │      0 │\n",
              "└───┴───────────┴──────────────┴────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
              "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ gnn       │ GraphSAGE    │ 46.4 K │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ pred      │ DotPredictor │      0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ train_auc │ AUROC        │      0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ val_auc   │ AUROC        │      0 │\n",
              "└───┴───────────┴──────────────┴────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 46.4 K                                                                     \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                      \n",
              "\u001b[1mTotal params\u001b[0m: 46.4 K                                                                         \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                    \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 46.4 K                                                                     \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                      \n",
              "<span style=\"font-weight: bold\">Total params</span>: 46.4 K                                                                         \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                    \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f40093e314784b32be4254270d1133f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ""
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nSy7kk3XL5GM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}