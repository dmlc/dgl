{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ITSM Data\n",
    "The purpose of this notebook is to prepare the data in a format suitable for machine learning. The dataset consists of a few numerical and many categorical attributes. The numerical attributes are discretized. The embedding for the categorical values is developed similar to developing embeddings for words in NLP (see https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html). Each categorical value is mapped to a unique integer. The encoded data that is presented to the embedding layer is a sequence of integers, with each integer corresponding to a word, This notebook performs this mapping. It also encodes unknown values to a 'UNKNOWN' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = \"incident_event_log.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "df['reassigned'] = df['reassigned'] = df['reassignment_count'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize the numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['sys_mod_count', 'reopen_count']\n",
    "dfn = df[numeric]\n",
    "dcols = []\n",
    "for col in numeric:\n",
    "    dlabel = 'D_' + col\n",
    "    labels = [dlabel +'_' + str(c) for c in range(5)]\n",
    "    dcols.append(dlabel)\n",
    "    dfn[dlabel] = pd.qcut(dfn[col].rank(method='first'),5, labels = labels, duplicates = 'drop')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate the attributes used for the analysis \n",
    "1. Remove the timestamp attributes\n",
    "2. Remove the numeric attributes. The discretized version of these attributes is added subsequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = df.columns.tolist()\n",
    "remove = [ 'made_sla', 'opened_at', 'resolved_at','sys_created_at', 'caller_id', 'closed_at',\\\n",
    "          'notify', 'sys_updated_by','sys_created_by', 'number', 'sys_updated_at', 'reassigned' ]\n",
    "exclude = remove + numeric\n",
    "keep = list(set(attributes) - set(exclude)) \n",
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_vars = df[keep]\n",
    "df_cat_vars = df_cat_vars.replace(to_replace = '?', value = 'UNKNOWN')\n",
    "df_cat_vars =  pd.concat([df_cat_vars, dfn[dcols]], axis = 1)\n",
    "df['made_sla'] = df['made_sla'].map({True: 1, False: 0})\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reassigned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_cat_vars.columns.tolist()\n",
    "vocab_size = 0\n",
    "for c in cols:\n",
    "    print(\"Num unique vals for category \" + str(c) + \" = \" + str(df_cat_vars[c].nunique()))\n",
    "    vocab_size += df_cat_vars[c].nunique()\n",
    "print(\"Vocab size: %s\" % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode the categorical values to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_VAL = 1\n",
    "cat_cols = df_cat_vars.columns.tolist()\n",
    "cat_int_map = {col: dict() for col in cat_cols}\n",
    "int_index = 2\n",
    "for c in cat_cols:\n",
    "    unique_col_values = df_cat_vars[c].unique().tolist()\n",
    "    col_int_map = cat_int_map[c]\n",
    "    for uv in unique_col_values:\n",
    "        if uv == 'UNKNOWN':\n",
    "            col_int_map[uv] = UNKNOWN_VAL\n",
    "        else:\n",
    "            col_int_map[uv] = int_index\n",
    "            int_index +=1\n",
    "    df_cat_vars[c] = df_cat_vars[c].map(cat_int_map[c])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cat_int_map = dict()\n",
    "for col in cat_int_map.keys():\n",
    "    for cat_val, int_map in cat_int_map[col].items():\n",
    "        combined_cat_int_map[cat_val] = int_map\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write preprocessed raw data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_cat_int_map = \"category_to_integer_map.csv\"\n",
    "df_map = pd.DataFrame(combined_cat_int_map, index = [0])\n",
    "df_map = df_map.T\n",
    "df_map = df_map.reset_index()\n",
    "df_map.columns = [\"cat_value\", \"assigned_integer\"]\n",
    "df_map.to_csv(fp_cat_int_map, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_cat_vars = ['number','sys_updated_at', 'reassigned'] \n",
    "df = pd.concat([df[add_to_cat_vars], df_cat_vars], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sys_updated_at'] = pd.to_datetime(df['sys_updated_at']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sys_updated_at'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = ['number', 'sys_updated_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'pp_batch_incident_event_log.csv'\n",
    "df.to_csv(fp, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reassigned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for learning\n",
    "The data used for learning has the raw data summarized by incident, i.e. , the raw data for each incident is grouped and summarized. A sample of the data used for learning can be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgb = df.groupby(by = ['number'])\n",
    "df_pp = df.loc[dfgb.sys_updated_at.idxmax()]\n",
    "df_pp = df_pp.reset_index()\n",
    "cols = df_pp.columns.tolist()\n",
    "cols.remove('index')\n",
    "df_pp = df_pp[cols]\n",
    "fprp = \"pp_recoded_incident_event_log.csv\"\n",
    "df_pp.to_csv(fprp, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp['reassigned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
